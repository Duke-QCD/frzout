# -*- coding: utf-8 -*-

import glob
import inspect
import os
import pickle
from contextlib import contextmanager

import numpy as np
import matplotlib.pyplot as plt
from scipy import integrate
from scipy import special
from scipy import stats
from sphinx.util import console

import frzout


sections = []


def section(function):
    sections.append(function)
    return function


def main(app):
    srcdir = app.builder.srcdir
    testsdir = os.path.join(app.config.html_static_path[0], 'tests')

    app.info(console.bold('generating test plots...'), nonl=True)

    # skip if all generated plot files are newer than this file
    plot_files = glob.glob(os.path.join(srcdir, testsdir, '*', '*.png'))
    if plot_files and all(
            os.path.getmtime(f) > os.path.getmtime(__file__)
            for f in plot_files
    ):
        app.info(' all up to date')
        return

    app.info()

    with open(os.path.join(srcdir, 'tests.rst'), 'w') as rst_file:
        rst_file.write(
            'Tests\n'
            '=====\n'
            'This page is automatically generated by '
            '`{basename} <https://github.com/{github_user}/{github_repo}'
            '/blob/master/doc/{basename}>`_ in the frzout repository.\n\n'
            'Each plot compares observables computed from the sampler '
            '(colored lines) to expected results (dark grey lines).\n'
            .format(
                basename=os.path.basename(__file__),
                **app.config.html_context
            )
        )

        for section in sections:
            title = section.__name__.replace('_', ' ').capitalize()
            app.info('  ' + title)
            rst_file.write(
                '\n{}\n{}\n{}\n'
                .format(title, '-'*len(title), inspect.getdoc(section))
            )

            reldir = os.path.join(testsdir, section.__name__)
            absdir = os.path.join(srcdir, reldir)
            os.makedirs(absdir, exist_ok=True)

            @contextmanager
            def axes(subsec=None, caption=None):
                if subsec:
                    app.info('    ' + subsec)
                    rst_file.write(
                        '\n{}\n{}'.format(subsec, '~'*len(subsec))
                    )
                if caption:
                    rst_file.write('\n{}\n'.format(caption))
                filename = '{:03d}.png'.format(axes.n)
                rst_file.write(
                    '\n.. image:: {0}\n   :target: {0}\n'
                    .format(os.path.join(reldir, filename))
                )
                yield plt.axes()
                plt.savefig(os.path.join(absdir, filename))
                plt.close()
                axes.n += 1

            axes.n = 0

            section(axes)


def setup(app):
    app.connect('builder-inited', main)


default_color = '#404040'
dashed_line = dict(color=default_color, linestyle='dashed')
color_cycle = [
    getattr(plt.cm, c)(.8) for c in
    ['Blues', 'Greens', 'Oranges', 'Purples']
]
font_size = 16

plt.rcdefaults()
plt.rcParams.update({
    'figure.figsize': (10, 6.18),
    'figure.dpi': 200,
    'figure.autolayout': True,
    'font.family': ['Lato'],
    'font.size': font_size,
    'legend.fontsize': font_size,
    'axes.labelsize': font_size,
    'axes.titlesize': font_size,
    'xtick.labelsize': font_size - 2,
    'ytick.labelsize': font_size - 2,
    'lines.linewidth': 1.25,
    'lines.markeredgewidth': .1,
    'patch.linewidth': 1.25,
    'axes.prop_cycle': plt.cycler('color', color_cycle),
    'axes.grid': True,
    'axes.axisbelow': True,
    'axes.facecolor': '#eaeaf2',
    'axes.linewidth': 0,
    'grid.linestyle': '-',
    'grid.linewidth': 1,
    'grid.color': '#fcfcfc',
    'savefig.facecolor': '#fcfcfc',
    'xtick.major.size': 0,
    'ytick.major.size': 0,
    'xtick.minor.size': 0,
    'ytick.minor.size': 0,
    'xtick.major.pad': 7,
    'ytick.major.pad': 7,
    'text.color': default_color,
    'axes.edgecolor': default_color,
    'axes.labelcolor': default_color,
    'xtick.color': default_color,
    'ytick.color': default_color,
    'legend.numpoints': 1,
    'legend.scatterpoints': 1,
    'legend.frameon': False,
    'image.interpolation': 'none',
})


id_parts = [
    (211, r'$\pi^\pm$'),
    (321, r'$K^\pm$'),
    (2212, r'$p \bar p$'),
]

hbarc = 0.1973269788


@section
def stationary_box(axes):
    """
    A single boost-invariant volume element with zero flow velocity.
    This is a rudimentary test case with easily-calculated observables.

    """
    volume = 3000.
    tau = 1.
    T = .15
    ymax = np.random.uniform(.5, .8)

    info = [frzout.species_dict[i] for (i, _) in id_parts]
    m = np.array([i['mass'] for i in info])
    g = np.array([i['degen'] for i in info])
    sign = np.array([-1 if i['boson'] else 1 for i in info])

    n = np.arange(1, 10)
    densities = g * m*m*T / (2*np.pi**2*hbarc**3) * (
        np.power.outer(-sign, n-1)/n *
        special.kn(2, np.outer(m, n)/T)
    ).sum(axis=1)
    yields = 2*ymax * volume * densities

    x = np.array([[tau, 0, 0]])
    sigma = np.array([[volume/tau, 0, 0]])
    v = np.zeros((1, 2))

    sampler = frzout.Sampler(x, sigma, v, T, ymax=ymax)

    nsamples = 1000
    samples = list(sampler.iter_samples(nsamples))
    parts = np.concatenate(samples).view(np.recarray)

    abs_ID = np.abs(parts.ID)
    E, px, py, pz = parts.p.T

    with axes(
            'Multiplicity distributions',
            'These are histograms of particle counts from many oversamples. '
            'Production of each species should be Poissonian:'
    ) as ax:
        for (i, label), N in zip(id_parts, yields):
            dist = stats.poisson(N)
            x = np.arange(*dist.ppf([.001, .999]).astype(int))
            ax.plot(x, dist.pmf(x), color=default_color)
            ax.hist([np.count_nonzero(s.ID == i) for s in samples],
                    bins=20, normed=True, histtype='step',
                    label=label.replace(r'\pm', '+').replace(r' \bar p', ''))

        ax.set_xlabel('Number of particles')
        ax.set_ylabel('Probability')
        ax.set_yticklabels([])
        ax.legend()

    with axes(caption=(
            'Overall particle production (all species) '
            'should also be Poissonian:'
    )) as ax:
        N = np.array([s.size for s in samples])
        dist = stats.poisson(sampler.navg)
        x = np.arange(*dist.ppf([.001, .999]).astype(int))
        ax.plot(x, dist.pmf(x), color=default_color)
        ax.hist(N, bins=30, normed=True,
                histtype='step', color=color_cycle[-1])
        ax.set_xlabel('Number of particles')
        ax.set_ylabel('Probability')
        ax.set_yticklabels([])

    with axes('Transverse momentum', 'Spectra are perfectly thermal:') as ax:
        pT = np.sqrt(px*px + py*py)
        pT_plot = np.linspace(0, 3, 1000)
        for k, (i, label) in enumerate(id_parts):
            mT = np.sqrt(frzout.species_dict[i]['mass']**2 + pT_plot**2)
            dN_dpT = 2*(
                volume * frzout.species_dict[i]['degen'] * (
                    np.outer(
                        2*mT,
                        (1 if frzout.species_dict[i]['boson'] else -1)**(n-1)
                    ) * special.k1(np.outer(mT, n)/T)
                ).sum(axis=1) / (2*np.pi*hbarc)**3
            )
            scale = 10**(-2*k)
            ax.plot(pT_plot, dN_dpT*scale, color=default_color)
            pT_ = pT[abs_ID == i]
            bins = np.linspace(0, pT_.max(), 50)
            ax.hist(
                pT_, bins=bins,
                weights=bins.size/bins.ptp()*scale/(
                    2*np.pi*pT_*2*ymax*nsamples),
                histtype='step', log=True,
                label=r'{} $({{\times}}10^{{{:d}}})$'.format(label, -2*k)
            )

        ax.set_xlabel('$p_T\ [\mathrm{GeV}]$')
        ax.set_ylabel('$1/2\pi p_T \: dN/dp_T\,dy\ [\mathrm{GeV}^{-2}]$')
        ax.yaxis.get_major_locator().base(100)
        ax.legend()

    with axes('Rapidity', '`dN/dy` should be flat:') as ax:
        y = .5*np.log((E + pz)/(E - pz))
        nbins = 50
        for (i, label), N in zip(id_parts, yields):
            ax.plot([-ymax, ymax], [2*N]*2, color=default_color)
            y_ = y[abs_ID == i]
            ax.hist(y_, bins=nbins, weights=np.full_like(y_, nbins/nsamples),
                    histtype='step', log=True, label=label)

        ax.set_xlabel('$y$')
        ax.set_ylabel('$dN/dy$')
        ax.legend(loc='lower center', ncol=len(id_parts))

    with axes('Azimuthal angle', '`dN/d\phi` should be flat:') as ax:
        phi = np.arctan2(py, px)
        nbins = 50
        for (i, label), N in zip(id_parts, yields):
            ax.plot([-np.pi, np.pi], [2*N]*2, color=default_color)
            phi_ = phi[abs_ID == i]
            ax.hist(phi_, bins=nbins,
                    weights=np.full_like(phi_, nbins/nsamples),
                    histtype='step', log=True, label=label)

        ax.set_xlim(-np.pi, np.pi)
        ax.set_xlabel('$\phi$')
        ax.set_ylabel('$dN/d\phi$')
        ax.legend(loc='lower center', ncol=len(id_parts))


@section
def moving_box(axes):
    """
    A single 3D volume element with nonzero flow velocity (but still zero
    normal vector to avoid negative contributions).  Histograms of sampled (x,
    y, z) momenta are compared to distributions computed by numerically
    integrating the distribution functions.

    """
    T = .15
    x = np.array([[1, 0, 0, 0]], dtype=float)

    for ID, name in id_parts:
        info = frzout.species_dict[ID]
        m = info['mass']
        g = info['degen']
        sign = -1 if info['boson'] else 1

        hrg = frzout.HRG(T, species=[ID])

        v = np.atleast_2d([np.random.uniform(-i, i) for i in [.5, .5, .7]])
        gamma = 1/np.sqrt(1 - (v*v).sum())
        ux, uy, uz = gamma*v.ravel()

        volume = 1e6/hrg.density()
        sigma = np.array([[volume, 0, 0, 0]])
        surface = frzout.Surface(x, sigma, v)

        parts = frzout.sample(surface, hrg)
        psamples = parts['p'].T[1:]

        # 3D lattice of momentum points
        P = [np.linspace(1.05*p.min(), 1.05*p.max(), 100) for p in psamples]
        Px, Py, Pz = np.meshgrid(*P, indexing='ij')
        dp = [p.ptp()/(p.size - 1) for p in P]

        # evaluate distribution function on lattice
        E = np.sqrt(m*m + Px*Px + Py*Py + Pz*Pz)
        f = 1/(np.exp((E*gamma - Px*ux - Py*uy - Pz*uz)/T) + sign)
        f *= 2*g/(2*np.pi*hbarc)**3

        with axes(name.replace('$', '`') + ' momentum') as ax:
            ax.set_yscale('log')

            ax.annotate(
                '\n'.join([
                    '$v_{} = {:+.4f}$'.format(*i)
                    for i in zip(['x', 'y', 'z'], v.flat)
                ]),
                (.04, .95), xycoords='axes fraction', ha='left', va='top'
            )

            nbins = 50
            for i, (p, c) in enumerate(zip(psamples, ['x', 'y', 'z'])):
                ax.hist(
                    p, bins=nbins,
                    weights=np.full_like(p, nbins/p.ptp()/volume),
                    histtype='step', label='$p_{}$'.format(c)
                )
                j, k = set(range(3)) - {i}
                # evaluate f along axis i by integrating out axes (j, k)
                ax.plot(
                    P[i], dp[j] * dp[k] * f.sum(axis=(j, k)),
                    color=default_color
                )

            ax.set_xlabel('$p\ [\mathrm{GeV}]$')
            ax.set_ylabel('$dN/dp\ [\mathrm{GeV}^{-1}]$')
            ax.legend()


@section
def resonance_mass_distributions(axes):
    """
    Verification of mass disributions for several resonance species.  Grey
    dashed lines are the Breit-Wigner distributions with mass-dependent width,
    grey solid lines are the same distributions with momentum integrated out,
    and colored lines are histograms of the sampled masses.

    """
    with axes() as ax:
        T = .15

        for ID, name in [
                (213, r'$\rho(770)$'),
                (2214, r'$\Delta(1232)$'),
                (22212, r'$N(1535)$'),
        ]:
            info = frzout.species_dict[ID]
            m0 = info['mass']
            w0 = info['width']
            m_min, m_max = info['mass_range']
            sign = -1 if info['boson'] else 1

            def bw(m):
                w = w0*np.sqrt((m - m_min)/(m0 - m_min))
                return w/((m - m0)**2 + w*w/4)

            def f(p, m):
                return p*p / (np.exp(np.sqrt(p*p + m*m)/T) + sign)

            m = np.linspace(m_min, m_max, 200)

            ax.plot(m, bw(m)/integrate.quad(bw, m_min, m_max)[0],
                    **dashed_line)

            bwf = np.array([
                integrate.quad(lambda p: bw(m_)*f(p, m_), 0, 5)[0] for m_ in m
            ]) / integrate.dblquad(
                lambda m_, p: bw(m_)*f(p, m_),
                0, 5, lambda _: m_min, lambda _: m_max
            )[0]

            ax.plot(m, bwf, color=default_color)

            hrg = frzout.HRG(T, species=[ID], res_width=True)

            x = np.array([[1, 0, 0, 0]], dtype=float)
            sigma = np.array([[1e6/hrg.density(), 0, 0, 0]])
            v = np.zeros((1, 3))
            surface = frzout.Surface(x, sigma, v)

            parts = frzout.sample(surface, hrg)
            m = np.sqrt(np.inner(parts['p']**2, [1, -1, -1, -1]))

            ax.hist(m, bins=64, normed=True, histtype='step', label=name)

        ax.set_xlim(0, 2)
        ax.set_xlabel('Mass [GeV]')
        ax.set_ylabel('Probability')
        ax.set_yticklabels([])

        ax.legend(loc='upper left')


@section
def equation_of_state(axes):
    """
    Comparison of thermodynamic quantities from phase-space integrals (grey
    dashed lines) to averages over sampled particles (solid colored lines).

    """
    with axes() as ax:
        volume = 1e6
        x = np.array([[1, 0, 0, 0]], dtype=float)
        sigma = np.array([[volume, 0, 0, 0]])
        v = np.zeros((1, 3))
        surface = frzout.Surface(x, sigma, v)

        def eos_quantities(T):
            hrg = frzout.HRG(T, res_width=False)
            parts = frzout.sample(surface, hrg)
            E = parts['p'][:, 0]
            psq = (parts['p'][:, 1:]**2).sum(axis=1)

            T3 = (T/hbarc)**3
            T4 = T * T3

            return [
                (hrg.density()/T3, parts.size/volume/T3),
                (hrg.energy_density()/T4, E.sum()/volume/T4),
                (3*hrg.pressure()/T4, 3*(psq/(3*E)).sum()/volume/T4),
            ]

        T = np.linspace(100, 180, 20)/1000

        for quantity, label in zip(
                np.array([eos_quantities(t) for t in T]).transpose(1, 2, 0),
                ['$n/T^3$', '$\epsilon/T^4$', '$3p/T^4$']
        ):
            ax.plot(T, quantity[1], label=label)
            ax.plot(T, quantity[0], **dashed_line)

        ax.set_xlabel('Temperature [GeV]')
        ax.legend(loc='upper left')


def sample_Tuv(surface, hrg):
    """
    Sample particles and compute the stress-energy tensor.

    """
    p = frzout.sample(surface, hrg)['p']
    return np.dot(p.T/p[:, 0], p) / surface.volume


def make_pi_dict(**kwargs):
    """
    Make a dict of pi components suitable for passing to Surface.

    """
    return {
        i: np.array([kwargs.get(i, 0.)])
        for i in ['xx', 'yy', 'xy', 'xz', 'yz']
    }


@section
def shear_viscous_corrections(axes):
    r"""
    Verification that the desired shear tensor `\pi^{\mu\nu}` is reproduced.
    This test case checks that nonzero `\pi^{xy}` is reproduced without
    changing the equilibrium pressure or energy density.  The algorithm starts
    to break down at very large shear pressure.

    The "shear and bulk" section below has additional checks.

    """
    hrg = frzout.HRG(.15, res_width=False)

    P0 = hrg.pressure()
    e0 = hrg.energy_density()

    x = np.array([[1., 0, 0, 0]])
    sigma = np.array([[1e6/hrg.density(), 0, 0, 0]])
    v = np.zeros((1, 3))

    pi_frac = np.linspace(-.5, .5, 11)

    Tuv = np.array([
        sample_Tuv(
            frzout.Surface(x, sigma, v, pi=make_pi_dict(xy=i*P0)),
            hrg
        ) for i in pi_frac
    ]).T

    P = Tuv.diagonal()[:, 1:].sum(axis=1)/3

    with axes() as ax:
        ax.plot(pi_frac, Tuv[1, 2]/P0, label='$\pi_{xy}$')
        ax.plot(pi_frac, pi_frac, **dashed_line)

        ax.plot(pi_frac, Tuv[1, 3]/P0, label='$\pi_{xz}$')
        ax.plot(pi_frac, P/P0 - 1, label='Pressure')
        ax.plot(pi_frac, Tuv[0, 0]/e0 - 1, label='Energy density')
        ax.axhline(0, **dashed_line)

        ax.set_xlim(pi_frac.min(), pi_frac.max())
        ax.set_ylim(pi_frac.min(), pi_frac.max())

        ax.set_xlabel('$\pi_{xy}/P_0$')
        ax.set_ylabel(
            '$\pi_{ij}/P_0,\ \Delta P/P_0,\ \Delta\epsilon/\epsilon_0$')
        ax.legend(loc='upper left')


@section
def bulk_viscous_corrections(axes):
    """
    Effect of bulk viscosity on thermodynamic quantities and momentum
    distributions.

    The total pressure is the sum of the equilibrium and bulk pressures:
    `P = P_0 + \Pi`.

    Most quantities are plotted as the relative change to their equilibrium
    values vs. the relative bulk pressure `\Pi/P_0`.  Colored lines are from
    samples and dashed lines are calculated.

    The algorithm starts to break down at very large bulk pressure, however in
    realistic events the bulk pressure is mostly small and negative, roughly
    `-0.2P_0 < \Pi < 0`.

    """
    T = .15
    hrg = frzout.HRG(T, res_width=False)

    volume = 2e6/hrg.density()
    x = np.array([[1., 0, 0, 0]])
    sigma = np.array([[volume, 0, 0, 0]])
    v = np.zeros((1, 3))

    def sample_bulk(Pi):
        surface = frzout.Surface(x, sigma, v, Pi=np.array([Pi]))
        parts = frzout.sample(surface, hrg)

        E = parts['p'][:, 0]
        psq = (parts['p'][:, 1:]**2).sum(axis=1)

        return (
            E.sum()/volume,
            (psq/(3*E)).sum()/volume,
            [(p.size/volume/2, p.mean()) for p in (
                np.sqrt(psq[np.abs(parts['ID']) == i]) for (i, _) in id_parts
            )]
        )

    P0 = hrg.pressure()
    e0 = hrg.energy_density()

    Pi_frac = np.linspace(-.5, .5, 21)
    Pi = Pi_frac * P0

    e, P, id_parts_samples = (
        np.array(i) for i in zip(*[sample_bulk(x*P0) for x in Pi_frac])
    )

    with axes(
            'Pressure and energy density',
            'Bulk pressure changes the effective pressure without changing '
            'the energy density.'
    ) as ax:
        ax.plot(Pi_frac, P/P0 - 1, label='Pressure')
        ax.plot(Pi_frac, Pi_frac, **dashed_line)

        ax.plot(Pi_frac, e/e0 - 1, label='Energy density')
        ax.axhline(0, **dashed_line)

        ax.set_xlim(Pi_frac.min(), Pi_frac.max())
        ax.set_ylim(Pi_frac.min(), Pi_frac.max())

        ax.set_xlabel('$\Pi/P_0$')
        ax.set_ylabel('$\Delta P/P_0,\ \Delta\epsilon/\epsilon_0$')
        ax.legend(loc='upper left')

    density, pavg = id_parts_samples.T

    zeta_over_tau = hrg.zeta_over_tau()
    cs2 = hrg.cs2()

    def f(p, ID, Pi=0):
        m, boson, g = (
            frzout.species_dict[ID][k] for k in ['mass', 'boson', 'degen']
        )
        s = -1 if boson else 1
        E = np.sqrt(m*m + p*p)
        f0 = 1/(np.exp(E/T) + s)
        df = Pi/(T*zeta_over_tau)*(p*p/(3*E) - cs2*E)*f0*(1 - s*f0)
        return g*(f0 + df)

    def int_f(ID, Pi=0, inner=lambda p: 1):
        return (4*np.pi)/(2*np.pi*hbarc)**3 * integrate.quad(
            lambda p: p*p*inner(p)*f(p, ID, Pi), 0, 10
        )[0]

    def calc_density(ID, Pi=0):
        return int_f(ID, Pi)

    def calc_pavg(ID, Pi=0):
        return int_f(ID, Pi, inner=lambda p: p) / calc_density(ID, Pi)

    with axes(
            'Particle densities',
            'Changes in density are proportional to bulk pressure '
            'by construction.'
    ) as ax:
        for n, (i, label) in zip(density, id_parts):
            n0 = calc_density(i)
            ncalc = np.array([calc_density(i, Pi_) for Pi_ in Pi])
            ax.plot(Pi_frac, n/n0 - 1, label=label)
            ax.plot(Pi_frac, ncalc/n0 - 1, **dashed_line)

        ax.set_xlim(Pi_frac.min(), Pi_frac.max())

        ax.set_xlabel('$\Pi/P_0$')
        ax.set_ylabel('$\Delta n/n_0$')
        ax.legend(loc='upper left')

    with axes('Average momenta') as ax:
        for p, (i, label) in zip(pavg, id_parts):
            p0 = calc_pavg(i)
            pcalc = np.array([calc_pavg(i, Pi_) for Pi_ in Pi])
            ax.plot(Pi_frac, p/p0 - 1, label=label)
            ax.plot(Pi_frac, pcalc/p0 - 1, **dashed_line)

        ax.set_xlim(Pi_frac.min(), Pi_frac.max())

        ax.set_xlabel('$\Pi/P_0$')
        ax.set_ylabel(r'$\Delta\langle p \rangle/\langle p \rangle_0$')
        ax.legend(loc='upper left')

    ID = 211
    n0 = calc_density(ID)
    pavg0 = calc_pavg(ID)

    with axes(
            'Distribution functions',
            'Pion distribution functions `f(p)` for different bulk pressures. '
            'Colored histograms are samples, solid lines are `f_0 + \delta f` '
            '(which goes negative for large momentum and bulk pressure), '
            'and dashed lines are the actual target distributions with '
            'rescaled momentum, `f_0(\lambda p)`.'
    ) as ax:
        nbins = 50
        w = nbins*(2*np.pi*hbarc)**3/(2*volume*4*np.pi)

        for k, Pi_frac in enumerate([0, -.1, -.3]):
            Pi = Pi_frac*P0
            parts = frzout.sample(
                frzout.Surface(x, sigma, v, Pi=np.array([Pi])),
                hrg
            )
            psq = (parts[np.abs(parts['ID']) == ID]['p'][:, 1:]**2).sum(axis=1)
            pmag = np.sqrt(psq)
            scale = 10**(-k)
            ax.hist(
                pmag, bins=nbins, weights=w*scale/psq/pmag.ptp(),
                histtype='step', log=True,
                label='$\Pi = ' + (
                    '0' if Pi_frac == 0 and k == 0 else
                    r'{}P_0\ (f \times 10^{{{:d}}})'.format(Pi_frac, -k)
                ) + '$'
            )

            p = np.linspace(0, pmag.max(), 200)
            ax.plot(p, scale*f(p, ID, Pi), color=default_color)

            n = calc_density(ID, Pi)
            pavg = calc_pavg(ID, Pi)
            ax.plot(p, n0/n*scale*f(p*pavg0/pavg, ID), **dashed_line)

        ax.set_xlabel('$p\ \mathrm{[GeV]}$')
        ax.set_ylabel('$f(p)$')
        ax.legend()


@section
def shear_and_bulk(axes):
    """
    Shear tensor with `\pi^{xx} = -\pi^{yy}` and all other components zero, and
    bulk pressure fixed at `\Pi = -0.1P_0`.  This is a very difficult test case
    but the algorithm remains accurate for small to moderate viscous pressure.

    """
    hrg = frzout.HRG(.15, res_width=False)

    P0 = hrg.pressure()
    e0 = hrg.energy_density()

    x = np.array([[1., 0, 0, 0]])
    sigma = np.array([[1e6/hrg.density(), 0, 0, 0]])
    v = np.zeros((1, 3))

    pi_frac = np.linspace(-.5, .5, 11)
    Pi_frac = -.1

    Tuv = np.array([
        sample_Tuv(
            frzout.Surface(
                x, sigma, v,
                pi=make_pi_dict(xx=i*P0, yy=-i*P0),
                Pi=np.array([Pi_frac*P0])
            ),
            hrg
        ) for i in pi_frac
    ]).T

    P = Tuv.diagonal()[:, 1:].sum(axis=1)/3

    with axes() as ax:
        ax.plot(pi_frac, (Tuv[1, 1] - P)/P0, label='$\pi_{xx}$')
        ax.plot(pi_frac, pi_frac, **dashed_line)

        ax.plot(pi_frac, (Tuv[2, 2] - P)/P0, label='$\pi_{yy}$')
        ax.plot(pi_frac, -pi_frac, **dashed_line)

        ax.plot(pi_frac, P/P0 - 1, label='Pressure')
        ax.axhline(Pi_frac, **dashed_line)

        ax.plot(pi_frac, Tuv[0, 0]/e0 - 1, label='Energy density')
        ax.axhline(0, **dashed_line)

        ax.set_xlim(pi_frac.min(), pi_frac.max())
        ax.set_ylim(pi_frac.min(), pi_frac.max())

        ax.set_xlabel('$\pi_{xx}/P_0,\ -\pi_{yy}/P_0$')
        ax.set_ylabel(
            '$\pi_{ij}/P_0,\ \Delta P/P_0,\ \Delta\epsilon/\epsilon_0$')
        ax.legend(loc='upper center')


def minus_sign(s):
    return s.replace('-', '\u2212')


@section
def stress_energy_tensor(axes):
    r"""
    Verification that the sampling algorithm reproduces the complete
    stress-energy tensor `T^{\mu\nu}` from hydrodynamics, including any viscous
    corrections.

    For each of the following, the flow velocity and viscous pressures are
    chosen randomly, particles are sampled, and the effective stress-energy
    tensor is computed by summing over the sampled particles.  The sampled
    tensor is then compared to the expectation from hydro.

    In the heatmap cells, the first number is sampled value for the given
    component of the tensor and the second number (in parentheses) is the
    expected value from hydro.  Cells are color-coded, where grey indicates
    perfect agreement, red indicates that the sampled value is large, and blue
    too small.  Some disagreement is expected due to statistical fluctuations
    from finite numbers of particles.

    Before each heatmap, the randomly chosen velocity and viscous pressures are
    listed.  The overall magnitude of shear pressure is quantified by the
    Lorentz scalar "pirel" = `\sqrt{\pi^{\mu\nu}\pi_{\mu\nu}/(e^2 + 3P_0^2)}`.

    """
    hrg = frzout.HRG(.15, res_width=False)

    P0 = hrg.pressure()
    e0 = hrg.energy_density()

    for _ in range(3):
        vmag = np.random.rand()
        cos_theta = np.random.uniform(-1, 1)
        sin_theta = np.sqrt(1 - cos_theta**2)
        phi = np.random.uniform(0, 2*np.pi)
        vx = vmag * sin_theta * np.cos(phi)
        vy = vmag * sin_theta * np.sin(phi)
        vz = vmag * cos_theta

        pixx, piyy, pixy, pixz, piyz = np.random.uniform(-.2, .2, 5)*P0
        Pi = np.random.uniform(-.2, .1)*P0

        surface = frzout.Surface(
            np.array([[1., 0, 0, 0]]),
            np.array([[2e6/hrg.density(), 0, 0, 0]]),
            np.array([[vx, vy, vz]]),
            pi={
                k[2:]: np.array([v])
                for k, v in locals().items()
                if k.startswith('pi')
            },
            Pi=np.array([Pi])
        )

        u = np.array([1, vx, vy, vz]) / np.sqrt(1 - vmag*vmag)

        pitt = (
            vx*vx*pixx + vy*vy*piyy - vz*vz*(pixx + piyy)
            + 2*vx*vy*pixy + 2*vx*vz*pixz + 2*vy*vz*piyz
        ) / (1 - vz*vz)
        pizz = pitt - pixx - piyy

        pitx = vx*pixx + vy*pixy + vz*pixz
        pity = vx*pixy + vy*piyy + vz*piyz
        pitz = vx*pixz + vy*piyz + vz*pizz

        piuv = np.array([
            [pitt, pitx, pity, pitz],
            [pitx, pixx, pixy, pixz],
            [pity, pixy, piyy, piyz],
            [pitz, pixz, piyz, pizz],
        ])

        uu = np.outer(u, u)
        g = np.array([1, -1, -1, -1], dtype=float)
        Delta = np.diag(g) - uu
        Tuv_check = e0*uu - (P0 + Pi)*Delta + piuv

        Tuv = u[0]*sample_Tuv(surface, hrg)

        Tmag = np.sqrt(e0*e0 + 3*P0*P0)
        pimag = np.sqrt(np.einsum('uv,uv,u,v', piuv, piuv, g, g))

        diff = (Tuv - Tuv_check)/np.maximum(np.abs(Tuv_check), .1*Tmag)
        tol = .05

        fmt = '{:.3f}'

        with axes(caption=minus_sign(', '.join([
                'v = (' + ', '.join(3*[fmt]).format(vx, vy, vz) + ')',
                'pirel = ' + fmt.format(pimag/Tmag),
                'Pi/P0 = ' + fmt.format(Pi/P0),
        ]))) as ax:
            ax.figure.set_size_inches(4.2, 4.2)
            ax.imshow(diff, cmap=plt.cm.coolwarm, vmin=-tol, vmax=tol)
            for i, j in np.ndindex(*Tuv.shape):
                ax.text(
                    i, j,
                    minus_sign('\n'.join(
                        f.format(x[i, j]) for f, x in [
                            ('{:.4f}', Tuv),
                            ('({:.4f})', Tuv_check),
                        ]
                    )),
                    ha='center', va='center',
                    fontsize=.75*font_size
                )
            ax.grid(False)
            ax.xaxis.tick_top()
            for i in ['x', 'y']:
                getattr(ax, 'set_{}ticks'.format(i))(range(4))
                getattr(ax, 'set_{}ticklabels'.format(i))(['t', 'x', 'y', 'z'])


def _realistic_surface_observables():
    """
    Compute observables for the "realistic surface" test case.

    """
    with open('test_surface.dat', 'rb') as f:
        surface_data = np.array(
            [l.split() for l in f if not l.startswith(b'#')],
            dtype=float
        )

    # 0    1  2  3         4         5         6    7
    # tau  x  y  dsigma_t  dsigma_x  dsigma_y  v_x  v_y
    # 8     9     10    11    12    13    14    15
    # pitt  pitx  pity  pixx  pixy  piyy  pizz  Pi
    x, sigma, v, _ = np.hsplit(surface_data, [3, 6, 8])
    pixx, pixy, piyy = surface_data.T[11:14]
    Pi = surface_data.T[15]

    sigma_ = np.zeros((sigma.shape[0], 4))
    sigma_[:, :3] = sigma
    sigma_[:, 1:] *= -1
    sigma_ *= x[:, :1]

    u_ = np.zeros((v.shape[0], 4))
    u_[:, 0] = 1
    u_[:, 1:3] = -v
    u_ /= np.sqrt(1 - np.square(v).sum(axis=1))[:, np.newaxis]

    vx, vy = v.T
    pi_uv = np.zeros((pixx.shape[0], 4, 4))
    pi_uv[:, 0, 0] = vx*vx*pixx + vy*vy*piyy + 2*vx*vy*pixy
    pi_uv[:, 1, 1] = pixx
    pi_uv[:, 2, 2] = piyy
    pi_uv[:, 3, 3] = pi_uv[:, 0, 0] - pixx - piyy
    pi_uv[:, 0, 1] = pi_uv[:, 1, 0] = -(vx*pixx + vy*pixy)
    pi_uv[:, 0, 2] = pi_uv[:, 2, 0] = -(vx*pixy + vy*piyy)
    pi_uv[:, 1, 2] = pi_uv[:, 2, 1] = pixy

    pT_max = 4
    pT_bins = np.linspace(0, pT_max, 41)
    pT = (pT_bins[:-1] + pT_bins[1:])/2
    delta_pT = pT_max/(pT_bins.size - 1)

    phi = np.linspace(0, 2*np.pi, 100, endpoint=False)

    eta, eta_weights = special.ps_roots(30)
    eta_max = 4
    eta *= eta_max
    eta_weights *= 2*eta_max

    T = .145
    hrg = frzout.HRG(T, res_width=False)
    eta_over_tau = hrg.eta_over_tau()
    zeta_over_tau = hrg.zeta_over_tau()
    cs2 = hrg.cs2()

    the_vn = [2, 3, 4]

    def calc_obs(ID):
        m = frzout.species_dict[ID]['mass']
        degen = frzout.species_dict[ID]['degen']
        sign = -1 if frzout.species_dict[ID]['boson'] else 1

        pT_, phi_, eta_ = np.meshgrid(pT, phi, eta)
        mT_ = np.sqrt(m*m + pT_*pT_)
        p = np.array([
            mT_*np.cosh(eta_),
            pT_*np.cos(phi_),
            pT_*np.sin(phi_),
            mT_*np.sinh(eta_)
        ]).T

        # ignore negative contributions
        psigma = np.inner(p, sigma_)
        psigma.clip(min=0, out=psigma)

        pu = np.inner(p, u_)
        with np.errstate(over='ignore'):
            f = 1/(np.exp(pu/T) + sign)

        df = f*(1 - sign*f) * (
            ((pu*pu - m*m)/(3*pu) - cs2*pu)/(zeta_over_tau*T)*Pi +
            np.einsum('ijku,ijkv,auv->ijka', p, p, pi_uv)/(2*pu*T*eta_over_tau)
        )
        f += df

        # (phi, pT) distribution
        phi_pT_dist = (
            2*degen *
            np.einsum('i,ijka,ijka->jk', eta_weights, psigma, f) /
            (2*np.pi*hbarc)**3 / phi.size
        )
        pT_dist = phi_pT_dist.sum(axis=1)

        # navg, pT dist, qn(pT)
        return (
            2*np.pi*delta_pT * np.inner(pT, pT_dist),
            pT_dist,
            [np.inner(np.exp(1j*n*phi), phi_pT_dist)/pT_dist for n in the_vn]
        )

    obs_calc = [calc_obs(i) for i, _ in id_parts]

    surface = frzout.Surface(
        x, sigma, v,
        pi=dict(xx=pixx, yy=piyy, xy=pixy),
        Pi=Pi
    )

    ngroups = 1000
    N = 1000  # nsamples per group
    nsamples = ngroups*N

    # need many samples for diff flow
    # too many to store all particles in memory -> accumulate observables
    obs_sampled = [(
        np.empty(nsamples, dtype=int),  # ID particle counts
        np.zeros_like(pT),  # pT distribution
        np.zeros((len(the_vn), pT.size)),  # diff flow
    ) for _ in id_parts]

    diff_flow_counts = [np.zeros_like(vn, dtype=int)
                        for (_, _, vn) in obs_sampled]

    from multiprocessing.pool import ThreadPool

    for k in range(ngroups):
        print('      group', k)
        # threading increases performance since sample() releases the GIL
        with ThreadPool() as pool:
            parts = pool.map(lambda _: frzout.sample(surface, hrg), range(N))
        # identified particle counts
        for (i, _), (counts, _, _) in zip(id_parts, obs_sampled):
            counts[k*N:(k+1)*N] = [
                np.count_nonzero(np.abs(p['ID']) == i) for p in parts
            ]
        # merge all samples
        parts = np.concatenate(parts)
        abs_ID = np.abs(parts['ID'])
        for (i, _), (_, pT_dist, vn_arr), dflow_counts, (_, _, qn_list) in zip(
                id_parts, obs_sampled, diff_flow_counts, obs_calc
        ):
            parts_ = parts[abs_ID == i]
            px, py = parts_['p'].T[1:3]
            pT_ = np.sqrt(px*px + py*py)
            phi_ = np.arctan2(py, px)
            # pT distribution
            pT_dist += np.histogram(pT_, bins=pT_bins, weights=1/pT_)[0]
            # differential flow
            for n, vn, dfc, qn in zip(the_vn, vn_arr, dflow_counts, qn_list):
                cosnphi = [
                    np.cos(n*phi_[np.fabs(pT_ - p) < .2] - npsi)
                    for (p, npsi) in zip(pT, np.arctan2(qn.imag, qn.real))
                ]
                vn += [c.sum() for c in cosnphi]
                dfc += [c.size for c in cosnphi]

    # normalize pT dists and diff flow
    for (_, pT_dist, vn), dflow_counts in zip(obs_sampled, diff_flow_counts):
        pT_dist /= 2*np.pi*nsamples*delta_pT
        vn /= dflow_counts

    return pT, the_vn, obs_calc, obs_sampled


@section
def realistic_surface(axes):
    """
    An event-by-event boost-invariant surface, calculated from a TRENTO Pb+Pb
    initial condition (mid centrality, b ~ 8 fm) and evolved through hydro with
    shear and bulk viscosities.  The hypersurface is evaluated on a very coarse
    grid (in the interest of speed), but is otherwise realistic.

    Standard observables are computed from the sampler (colored lines) and by
    integrating the surface (grey dashed lines).  Negative contributions are
    neglected in both cases.

    """
    try:
        with open('test_surface_observables.pkl', 'rb') as f:
            obs = pickle.load(f)
    except FileNotFoundError:
        obs = _realistic_surface_observables()
        with open('test_surface_observables.pkl', 'wb') as f:
            pickle.dump(obs, f, pickle.HIGHEST_PROTOCOL)

    pT, the_vn, obs_calc, obs_sampled = obs

    with axes(
            'Multiplicity distributions',
            'Particle production is Poissonian with mean '
            'given by the fully integrated surface.'
    ) as ax:
        for (i, label), (navg, _, _), (counts, _, _) in zip(
                id_parts, obs_calc, obs_sampled
        ):
            dist = stats.poisson(navg)
            x = np.arange(*dist.ppf([.0001, .9999]).astype(int))
            ax.hist(
                counts, bins=(np.arange(counts.min(), counts.max() + 2) - .5),
                normed=True, histtype='step', label=label
            )
            ax.plot(x, dist.pmf(x), **dashed_line)

        ax.set_xlabel('Number of particles')
        ax.set_ylabel('Probability')
        ax.set_yticklabels([])
        ax.legend()

    with axes('Transverse momentum distributions') as ax:
        ax.set_yscale('log')
        for (i, label), (_, pT_dist_calc, _), (_, pT_dist_sampled, _) in zip(
                id_parts, obs_calc, obs_sampled
        ):
            ax.plot(pT, pT_dist_sampled, label=label)
            ax.plot(pT, pT_dist_calc, **dashed_line)

        ax.set_xlabel('$p_T\ [\mathrm{GeV}]$')
        ax.set_ylabel('$1/2\pi p_T \: dN/dp_T\,dy\ [\mathrm{GeV}^{-2}]$')
        ax.legend()

    iflow = np.searchsorted(pT, 3, side='right')

    for k, n in enumerate(the_vn):
        args = (
            'Flow',
            'Calculating differential flow from the sampler requires huge '
            'quantities of particles and even then remains somewhat noisy '
            'at very small and large momentum.  It also tends to look "flat" '
            'due to binning effects.'
        ) if k == 0 else ()
        with axes(*args) as ax:
            for (i, label), (_, _, qn_calc), (_, _, vn_sampled) in zip(
                    id_parts, obs_calc, obs_sampled
            ):
                ax.plot(pT[:iflow], vn_sampled[k][:iflow], label=label)
                ax.plot(pT[:iflow], np.abs(qn_calc[k][:iflow]), **dashed_line)

            ax.set_ylim(ymin=0)
            ax.set_xlabel('$p_T\ \mathrm{[GeV]}$')
            ax.set_ylabel('$v_{}(p_T)$'.format(n))
            ax.set_title('$v_{}$'.format(n), fontsize=1.2*font_size)
            ax.legend(loc='upper left')
